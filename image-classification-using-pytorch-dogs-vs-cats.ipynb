{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1003830,"sourceType":"datasetVersion","datasetId":550917}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torchvision\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nDATA_PATH = \"/kaggle/input/microsoft-catsvsdogs-dataset/PetImages\"\n\nfrom torchvision.datasets.folder import default_loader\nclass CustomDatasetFolder(datasets.DatasetFolder):\n    def __init__(self, root, loader=default_loader, extensions=None, transform=None, target_transform=None, is_valid_file=None):\n        super(CustomDatasetFolder, self).__init__(root, loader, extensions, transform, target_transform, is_valid_file)\n\n    def find_ignore_indices(self, ignore_paths):\n        ignore_indices = []\n        for ignore_path in ignore_paths:\n            for i, (path, _) in enumerate(self.samples):\n                if path == ignore_path:\n                    ignore_indices.append(i)\n        return ignore_indices\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        sample = self.loader(path)\n\n        if self.transform is not None:\n            sample = self.transform(sample)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return sample, target\n\n    def update_dataset(self, ignore_paths):\n        ignore_indices = self.find_ignore_indices(ignore_paths)\n\n        # Collect samples and targets to keep\n        updated_samples = [sample for i, sample in enumerate(self.samples) if i not in ignore_indices]\n        updated_targets = [target for i, target in enumerate(self.targets) if i not in ignore_indices]\n\n        # Update the dataset\n        self.samples = updated_samples\n        self.targets = updated_targets\n\nIGNORE_PATHS = [\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog/11702.jpg',\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat/666.jpg']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-20T09:35:41.136012Z","iopub.execute_input":"2024-01-20T09:35:41.136398Z","iopub.status.idle":"2024-01-20T09:35:41.153188Z","shell.execute_reply.started":"2024-01-20T09:35:41.136362Z","shell.execute_reply":"2024-01-20T09:35:41.151792Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\n# Define your transformation\ntransformation_steps = transforms.Compose([\n    transforms.Resize((64, 64)),  # Adjust the size as needed\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n    transforms.ToTensor()\n])\n\n# Load your dataset\ndataset = CustomDatasetFolder(\n    root=DATA_PATH, \n    loader=torchvision.datasets.folder.default_loader, \n    transform=transformation_steps,\n    extensions=['jpg']\n)\ndataset.update_dataset(IGNORE_PATHS)\n\n# Define the split ratios\ntrain_ratio = 0.8\ntest_ratio = 1 - train_ratio\n\n# Calculate the number of samples for each split\nnum_train = int(train_ratio * len(dataset))\nnum_test = len(dataset) - num_train\n\n# Split the dataset\ntrain_set, test_set = random_split(dataset, [num_train, num_test])\n\n# Create data loaders\nBATCH_SIZE = 1\nNUM_WORKERS = os.cpu_count()\ntrain_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\ntest_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T09:35:41.155304Z","iopub.execute_input":"2024-01-20T09:35:41.155744Z","iopub.status.idle":"2024-01-20T09:35:45.050141Z","shell.execute_reply.started":"2024-01-20T09:35:41.155705Z","shell.execute_reply":"2024-01-20T09:35:45.049247Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\nclass DogCatClassifier(nn.Module):\n    def __init__(self, \n               input_shape: int,\n               output_shape: int) -> None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n        self.conv6 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n\n        # Global Average Pooling layer\n        self.global_avg_pooling = nn.AdaptiveAvgPool2d(1)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(256, 1024)\n        self.fc2 = nn.Linear(1024, 2)  # Assuming 2 classes for the final layer\n\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.pool2(x)\n\n        x = F.relu(self.conv5(x))\n        x = F.relu(self.conv6(x))\n\n        x = self.global_avg_pooling(x)\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n\n        x = F.relu(self.fc1(x))\n        x = F.softmax(self.fc2(x), dim=1)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-20T09:35:45.051985Z","iopub.execute_input":"2024-01-20T09:35:45.052791Z","iopub.status.idle":"2024-01-20T09:35:45.065648Z","shell.execute_reply.started":"2024-01-20T09:35:45.052752Z","shell.execute_reply":"2024-01-20T09:35:45.064743Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nimport warnings\n\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = DogCatClassifier(\n    input_shape=3,\n    output_shape=2).to(device)\n\nloss_fn = nn.CrossEntropyLoss() \noptimizer = torch.optim.Adam(\n    params=model.parameters(),\n    lr=0.0001\n)\n# step_size = 5\n# gamma = 0.1\n# scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n# Set number of epochs\nEPOCHS = 20\ntotal_dataset_size = len(train_dataloader)\n\nfor epoch in tqdm(range(EPOCHS)):\n    model.train()\n    # Training\n    train_loss, train_acc = 0, 0\n    for batch, (X, y) in enumerate(train_dataloader):\n        if (batch // BATCH_SIZE) % 100 == 0:\n            print(f\"\\rEpoch: {epoch}/{EPOCHS} | Batch: {batch}/{total_dataset_size}\", end=\"\", flush=True)\n        X, y = X.to(device), y.to(device)\n        y_pred = model(X) # 1. Forward pass\n        loss = loss_fn(y_pred, y) # 2. Calculate the loss\n        train_loss += loss.item()\n        optimizer.zero_grad() # 3. Optimizer zero grad\n        loss.backward() # 4. Loss backward\n        optimizer.step()# 5. Optimizer step\n        # Calculate accuracy metric\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n\n    # Adjust metrics to get average loss and accuracy per batch\n    train_loss = train_loss / len(train_dataloader)\n    train_acc = train_acc / len(train_dataloader) \n    \n    # Testing\n    test_loss, test_acc = 0,0\n    model.eval()\n    with torch.inference_mode():\n        for batch, (X, y) in enumerate(test_dataloader):\n            X, y = X.to(device), y.to(device)\n            test_pred_logits = model(X)\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n        test_loss = test_loss / len(test_dataloader)\n        test_acc = test_acc / len(test_dataloader)\n    print(f\" | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T09:35:45.066902Z","iopub.execute_input":"2024-01-20T09:35:45.067471Z","iopub.status.idle":"2024-01-20T10:13:43.319749Z","shell.execute_reply.started":"2024-01-20T09:35:45.067436Z","shell.execute_reply":"2024-01-20T10:13:43.318688Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7fd337198ab4ac6a256fca12f991a3c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0/20 | Batch: 19900/19998 | Train loss: 0.6799 | Train acc: 0.5569 | Test loss: 0.6511 | Test acc: 0.6190\nEpoch: 1/20 | Batch: 19900/19998 | Train loss: 0.6540 | Train acc: 0.6159 | Test loss: 0.6345 | Test acc: 0.6496\nEpoch: 2/20 | Batch: 19900/19998 | Train loss: 0.6401 | Train acc: 0.6385 | Test loss: 0.6181 | Test acc: 0.6674\nEpoch: 3/20 | Batch: 19900/19998 | Train loss: 0.6488 | Train acc: 0.6351 | Test loss: 0.6289 | Test acc: 0.6422\nEpoch: 4/20 | Batch: 19900/19998 | Train loss: 0.6205 | Train acc: 0.6622 | Test loss: 0.6325 | Test acc: 0.6362\nEpoch: 5/20 | Batch: 19900/19998 | Train loss: 0.6144 | Train acc: 0.6687 | Test loss: 0.6101 | Test acc: 0.6754\nEpoch: 6/20 | Batch: 19900/19998 | Train loss: 0.6086 | Train acc: 0.6778 | Test loss: 0.5989 | Test acc: 0.6952\nEpoch: 7/20 | Batch: 19900/19998 | Train loss: 0.6058 | Train acc: 0.6817 | Test loss: 0.5951 | Test acc: 0.6940\nEpoch: 8/20 | Batch: 19900/19998 | Train loss: 0.5958 | Train acc: 0.6937 | Test loss: 0.6298 | Test acc: 0.6542\nEpoch: 9/20 | Batch: 19900/19998 | Train loss: 0.5907 | Train acc: 0.7007 | Test loss: 0.5797 | Test acc: 0.7160\nEpoch: 10/20 | Batch: 19900/19998 | Train loss: 0.5843 | Train acc: 0.7052 | Test loss: 0.5687 | Test acc: 0.7218\nEpoch: 11/20 | Batch: 19900/19998 | Train loss: 0.5761 | Train acc: 0.7178 | Test loss: 0.5779 | Test acc: 0.7192\nEpoch: 12/20 | Batch: 19900/19998 | Train loss: 0.5713 | Train acc: 0.7261 | Test loss: 0.6233 | Test acc: 0.6678\nEpoch: 13/20 | Batch: 19900/19998 | Train loss: 0.5696 | Train acc: 0.7235 | Test loss: 0.5580 | Test acc: 0.7366\nEpoch: 14/20 | Batch: 19900/19998 | Train loss: 0.5645 | Train acc: 0.7297 | Test loss: 0.5649 | Test acc: 0.7256\nEpoch: 15/20 | Batch: 19900/19998 | Train loss: 0.5592 | Train acc: 0.7382 | Test loss: 0.5498 | Test acc: 0.7474\nEpoch: 16/20 | Batch: 19900/19998 | Train loss: 0.5550 | Train acc: 0.7412 | Test loss: 0.6202 | Test acc: 0.6712\nEpoch: 17/20 | Batch: 19900/19998 | Train loss: 0.5509 | Train acc: 0.7461 | Test loss: 0.5393 | Test acc: 0.7520\nEpoch: 18/20 | Batch: 19900/19998 | Train loss: 0.5481 | Train acc: 0.7472 | Test loss: 0.5331 | Test acc: 0.7586\nEpoch: 19/20 | Batch: 19900/19998 | Train loss: 0.5422 | Train acc: 0.7561 | Test loss: 0.5486 | Test acc: 0.7470\n","output_type":"stream"}]},{"cell_type":"code","source":"# working \n# lr = 0.0001, epochs = 20, ADAM\n\n\n\n# Testing\n# changed the batch size form 1 to 64 and resize from 64x64 to 150x150","metadata":{"execution":{"iopub.status.busy":"2024-01-20T10:13:43.322173Z","iopub.execute_input":"2024-01-20T10:13:43.322485Z","iopub.status.idle":"2024-01-20T10:13:43.327153Z","shell.execute_reply.started":"2024-01-20T10:13:43.322453Z","shell.execute_reply":"2024-01-20T10:13:43.326312Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}